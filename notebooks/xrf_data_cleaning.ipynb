{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine xrf data from different days (sessions) into one dataframe\n",
    "directory = r'../data/raw/XRF_data' #location of csv files\n",
    "counter = 0\n",
    "for filename in os.listdir(directory): # cycle through csv files\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory, filename)        \n",
    "\n",
    "        date = filename.split(\"-\",1)[1].split(\".\",1)[0] # get date from filename\n",
    "\n",
    "        if counter == 0: # create dataframe with 1st file only\n",
    "            xrf_data = pd.read_csv(file_path, encoding='utf-16', sep=\"\\t\")\n",
    "            xrf_data = xrf_data.iloc[1:] # remove empty row\n",
    "            xrf_data[\"date\"] = date # add date column\n",
    "\n",
    "        else: # append for all other files\n",
    "            df = pd.read_csv(file_path, encoding='utf-16', sep=\"\\t\")\n",
    "            df = df.iloc[1:] # remove empty row\n",
    "            df[\"date\"] = date # add date column\n",
    "\n",
    "            xrf_data = xrf_data.append(df) # combine data\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean xrf data\n",
    "xrf_data = xrf_data.drop(columns=[\"Analyst\", \"Field Label 1\"]) # drop unnecessary columns\n",
    "xrf_data = xrf_data.rename(columns={\"Field 1\": \"sample_id\"}) # rename sample ID column\n",
    "xrf_data.loc[xrf_data[\"sample_id\"]==\"UNKNOWN\", \"sample_id\"] = \"TE2-009\" # replace unknown sample ID\n",
    "xrf_data[\"date\"] = pd.to_datetime(xrf_data[\"date\"], format=\"%m-%d-%Y\").dt.date # make replace dates with date-time object\n",
    "xrf_data.dropna(subset=[\"sample_id\"], inplace=True) # remove empty rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create dataframes for sample processing\n",
    "sample_processing_path = \"../data/raw/EPSC 552 sample processing.xlsx\"\n",
    "\n",
    "analysis_log = pd.read_excel(sample_processing_path, sheet_name=\"lab_processing\") # main sample processing\n",
    "sample_list  = pd.read_excel(sample_processing_path, sheet_name=\"samples\") # list of samples (and their types)\n",
    "person_dict  = pd.read_excel(sample_processing_path, sheet_name=\"person_dictionary\") # list of people (and their groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_log.dropna(subset=[\"sample_id\"], inplace=True) #remove empty rows\n",
    "sample_list.dropna( subset=[\"sample_id\"], inplace=True) #remove empty rows\n",
    "person_dict.dropna( subset=[\"person_id\"], inplace=True) #remove empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean main sample processing dataframe\n",
    "analysis_log[\"date\"] = pd.to_datetime(analysis_log[\"time_entered\"], format=\"%m-%d-%Y %H:%M:%S.%f\").dt.date\n",
    "analysis_log[\"analysis_order_index\"] = analysis_log[\"analysis_order_index\"].astype(\"int32\") # change dtype from float to integer\n",
    "analysis_log.drop(analysis_log[analysis_log[\"process\"] != \"xrf analysis\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## join to get group ID\n",
    "analysis_log = pd.merge(analysis_log, person_dict, how=\"inner\", left_on=\"person_1\", right_on=\"person_id\")\n",
    "analysis_log.drop(columns=[\"person_1\", \"person_2\", \"person_3\", \"person_id\", \"description\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "## join to get sample type and QAQC type\n",
    "analysis_log = pd.merge(analysis_log, sample_list, how=\"inner\", on=\"sample_id\")\n",
    "analysis_log.drop(columns=[\"sample_type_2\"], inplace=True)\n",
    "analysis_log.rename(columns={\"sample_type_1\": \"sample_type\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine comments from different dataframes\n",
    "analysis_log[\"comments\"] = analysis_log[\"comments_x\"].astype(\"str\").replace({\"nan\": \"\"}) + analysis_log[\"comments_y\"].astype(\"str\").replace({\"nan\": \"\"})\n",
    "analysis_log.drop(columns=[\"process\", \"time_entered\", \"last_modified\", \"comments_x\", \"comments_y\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ensure that case of sample IDs will match\n",
    "xrf_data[\"sample_id\"] = xrf_data[\"sample_id\"].apply(lambda sample_id: sample_id if (sample_id.startswith(\"GR\")) or (sample_id.startswith(\"TE\")) else sample_id.lower())\n",
    "analysis_log[\"sample_id\"] = analysis_log[\"sample_id\"].apply(lambda sample_id: sample_id if (sample_id.startswith(\"GR\")) or (sample_id.startswith(\"TE\")) else sample_id.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combine xrf and sample processing data\n",
    "xrf_data = pd.merge(xrf_data, analysis_log, how=\"inner\", on=[\"sample_id\", \"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reset index column\n",
    "xrf_data.sort_values(by=\"analysis_order_index\", inplace=True)\n",
    "xrf_data.reset_index(inplace=True, drop=True)\n",
    "xrf_data.drop(columns=[\"analysis_order_index\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop any empty columns (e.g., no data for an element)\n",
    "xrf_data.dropna(axis=1, how=\"all\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change order of columns\n",
    "columns = xrf_data.columns\n",
    "headers_to_move = [\"date\", \"group\", \"sample_type\", \"qaqc_type\"]\n",
    "\n",
    "columns = [column for column in columns if column not in headers_to_move]\n",
    "for header in reversed(headers_to_move):\n",
    "    columns.insert(1, header)\n",
    "\n",
    "xrf_data = xrf_data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export data to excel file\n",
    "xrf_data.to_excel('../data/interim/xrf_data_clean.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da7f753086fad63f468c7afa1043fdfff877310ce7148e2af11ff3397961b305"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('EPSC-552-Mont-St-Hilaire': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
