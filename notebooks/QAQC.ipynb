{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from mendeleev.fetch import fetch_table\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from itertools import compress\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from source.outliers import *\n",
    "from source.interactive_plots import interactive_linear_regression_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "xrf_data = pd.read_csv(\"../data/interim/xrf_data_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "standards_data = xrf_data[xrf_data[\"qaqc_type\"]==\"standard\"]\n",
    "lab_duplicates_data = xrf_data[xrf_data[\"qaqc_type\"]==\"lab duplicate\"]\n",
    "field_duplicates_data = xrf_data[xrf_data[\"qaqc_type\"]==\"field duplicate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "standards = standards_data[\"sample_id\"].unique()\n",
    "lab_duplicates = lab_duplicates_data[\"sample_id\"].unique()\n",
    "field_duplicates = field_duplicates_data[\"sample_id\"].unique()\n",
    "dates = xrf_data[\"date\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get elements analyzed\n",
    "columns = xrf_data.columns.tolist()\n",
    "ptable = fetch_table('elements').symbol.to_list()\n",
    "elements = [elem for elem in columns if elem in ptable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_date = \"2021-10-06\"\n",
    "\n",
    "standards_drift_data = standards_data.copy()\n",
    "\n",
    "for standard in standards_data[\"sample_id\"].unique(): \n",
    "\n",
    "    initial_measurement = standards_data.loc[(standards_data[\"sample_id\"] == standard) & \\\n",
    "                                             (standards_data[\"date\"]      == initial_date)]\n",
    "\n",
    "    other_measurements  = standards_data.loc[(standards_data[\"sample_id\"]  == standard) & \\\n",
    "                                            (standards_data[\"date\"]       != initial_date)]\n",
    "\n",
    "    diff = other_measurements.loc[:,elements] - initial_measurement.loc[:, elements].iloc[0]\n",
    "    \n",
    "    standards_drift_data.loc[other_measurements.index, elements] = diff\n",
    "\n",
    "    standards_drift_data.drop(initial_measurement.index, axis=0, inplace=True)\n",
    "    \n",
    "standards_drift_data.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = detect_outliers_Dixons_Q(elements, standards_drift_data)\n",
    "save_outliers(outliers);\n",
    "outliers = get_outliers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "standards_drift_data = remove_outliers(outliers, standards_drift_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No drift correction necessary\n"
     ]
    }
   ],
   "source": [
    "# initialize dictionary to hold drift correction lin. reg. models for each element\n",
    "reg = {}\n",
    "\n",
    "score_threshold = 0.5 # threshold R^2 value below which no drift correction is necessary\n",
    "drift_correction_eval = []\n",
    "\n",
    "for element in elements:\n",
    "    data_train = standards_drift_data[[\"date\", element]].dropna(axis=0)\n",
    "    x_train = [datetime.strptime(date, \"%Y-%m-%d\") for date in data_train[\"date\"]]\n",
    "    x_train = pd.Series(x_train).map(datetime.toordinal)\n",
    "    x_train = x_train.to_numpy()[:, None] # slice to add extra dim. (req. by model)\n",
    "    y_train = data_train[element]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(x_train,y_train)\n",
    "\n",
    "    reg[element] = {}\n",
    "\n",
    "    reg[element][\"model\"]   = model\n",
    "    reg[element][\"x_train\"] = x_train\n",
    "    reg[element][\"y_train\"] = y_train\n",
    "    reg[element][\"score\"]   = model.score(x_train,y_train)\n",
    "    if reg[element][\"score\"] > 0.5: \n",
    "        drift_correction_eval.append(True)\n",
    "    else:\n",
    "        drift_correction_eval.append(False)\n",
    "\n",
    "    x_predict = np.unique(x_train.squeeze())[:, None]\n",
    "    y_predict = model.predict(x_predict)\n",
    "    \n",
    "    reg[element][\"x_predict\"] = x_predict\n",
    "    reg[element][\"y_predict\"] = y_predict\n",
    "\n",
    "if len(list(compress(elements, drift_correction_eval))) == 0: \n",
    "    print(\"No drift correction necessary\") \n",
    "else: \n",
    "    print(\"Drift correction necessary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21dd5753ed254ba5abb280de00a6e816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Elements', options=('Au', 'As', 'Sb', 'Ag', 'Ba', 'Bi', 'Câ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dropdown_buttons = {\n",
    "    \"data\": \n",
    "        {\n",
    "            \"name\": \"Elements\", \n",
    "            \"columns\": list(reg.keys())\n",
    "        }\n",
    "    }\n",
    "    \n",
    "interactive_linear_regression_plot(dropdown_buttons, reg, x_axis_label=\"Dates\", y_axis_label=\"Concentration (ppm)\", title=\"Difference in reported concentration from initial standard analysis regressed on time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da7f753086fad63f468c7afa1043fdfff877310ce7148e2af11ff3397961b305"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('EPSC-552-Mont-St-Hilaire': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
